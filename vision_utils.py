import atexit
import os, uuid, time, base64, requests, logging
from io import BytesIO
from PIL import Image
from apscheduler.schedulers.gevent import GeventScheduler   # â† é‡ç‚¹
from typing import Tuple
from config import (
    UPLOAD_FOLDER, PUBLIC_BASE_URL,
    TARGET_BYTES, MIN_QUALITY,
    ARK_API_KEY,  ARK_REGION, ARK_ENDPOINT
)

log = logging.getLogger("vision")
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸…ç† uploads/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_sched = GeventScheduler()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸…ç† uploads/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _clear_upload_folder():
    now = time.time()
    for fn in os.listdir(UPLOAD_FOLDER):
        p = os.path.join(UPLOAD_FOLDER, fn)
        try:
            if os.path.isfile(p) and now - os.path.getmtime(p) > 30:
                os.remove(p)
                log.debug("ðŸ—‘ï¸  rm %s", p)
        except Exception as e:
            log.warning("rm %s fail: %s", p, e)

def start_cleanup_scheduler():
    _sched.add_job(_clear_upload_folder, "interval", seconds=120)
    _sched.start()
    atexit.register(lambda: _sched.shutdown(wait=False))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºç¡€æ­¥éª¤å°è£… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt():
    mem_dir = os.path.join(os.getcwd(), "voicememory")
    os.makedirs(mem_dir, exist_ok=True)
    # fallback to Dify
    epi = open(os.path.join(mem_dir, "Episodicmemory.txt"), "r", encoding="utf-8").read() if os.path.exists(os.path.join(mem_dir, "Episodicmemory.txt")) else ""
    short = open(os.path.join(mem_dir, "voicememory.txt"), "r", encoding="utf-8").read() if os.path.exists(os.path.join(mem_dir, "voicememory.txt")) else ""
    prompt = f"éžå¸¸è¯¦ç»†è€Œä¸”å¯Œæœ‰åˆ›é€ åŠ›çš„æè¿°å›¾ç‰‡çš„å†…å®¹ï¼Œå¯¹çœ‹åˆ°çš„äººè„¸éœ€è¦åšè¯¦ç»†æè¿°ï¼Œå¯ä»¥å‘æŒ¥æƒ³è±¡å’Œåˆ›æ„é‡Œé¢éƒ½æœ‰ä»€ä¹ˆ"
    return prompt
def _decode_and_resize(b64: str) -> Tuple[bytes, str]:
    """Base64 â†’ åŽ‹ç¼© JPEG â†’ å†™ uploads/ â†’ è¿”å›ž (bytes, public_url)"""
    _, encoded = (b64.split(",", 1) if b64.startswith("data:") else (None, b64))
    raw = base64.b64decode(encoded)
    img = Image.open(BytesIO(raw)).convert("RGB")

    quality = 90
    buf = BytesIO()
    while quality >= MIN_QUALITY:
        buf.truncate(0); buf.seek(0)
        img.save(buf, format="JPEG", quality=quality, optimize=True)
        if buf.tell() <= TARGET_BYTES:
            break
        quality -= 10
    else:
        raise RuntimeError("image too large even @40%")

    fname = f"{uuid.uuid4()}.jpg"
    path  = os.path.join(UPLOAD_FOLDER, fname)
    with open(path, "wb") as f:
        f.write(buf.getvalue())

    url = f"{PUBLIC_BASE_URL}/uploads/{fname}"
    log.info("ðŸ“¸ saved %s (%d KB)", fname, buf.tell()//1024)
    return buf.getvalue(), url

def _ask_vision_llm(public_url: str) -> str:
    """è°ƒç”¨ Ark/Difyï¼Œè¿”å›žçº¯æ–‡æœ¬ç­”æ¡ˆ"""
    prompt = build_prompt()
    payload = {
        "model": ARK_ENDPOINT,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type":"text","text":prompt},
                    {"type":"image_url","image_url":{"url": public_url}}
                ]
            }
        ]
    }
    r = requests.post(
        ARK_REGION,
        headers={"Authorization": f"Bearer {ARK_API_KEY}",
                 "Content-Type": "application/json"},
        json=payload,
        timeout=180
    )
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"].strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¯¹å¤–ä¸»å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_base64_image(b64: str) -> str:
    """
    â€¢ å†™ uploads/
    â€¢ è°ƒ vision LLM
    â€¢ è¿”å›ž text answer
    """
    _, url = _decode_and_resize(b64)
    answer = _ask_vision_llm(url)
    return answer
